from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when, collect_list, explode, sum as spark_sum
from pyspark.sql.types import StructType, StructField, StringType, DoubleType
from pyspark import SparkContext, StorageLevel
import sys
from typing import List, Tuple, Dict


class PersonalizedPageRank:
    def __init__(self, app_name="PersonalizedPageRank"):
        """Khá»Ÿi táº¡o Spark Session"""
        self.spark = SparkSession.builder \
            .appName(app_name) \
            .master("local[*]") \
            .config("spark.sql.adaptive.enabled", "true") \
            .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
            .getOrCreate()

        self.sc = self.spark.sparkContext
        self.sc.setLogLevel("WARN")

    def compute_personalized_pagerank(
            self,
            edges: List[Tuple[str, str]],
            source_page: str,
            damping_factor: float = 0.85,
            max_iterations: int = 100,
            tolerance: float = 1e-6
    ) -> List[Tuple[str, float]]:
        """
        TÃ­nh Personalized PageRank sá»­ dá»¥ng RDD

        Args:
            edges: Danh sÃ¡ch cÃ¡c cáº¡nh [(from, to), ...]
            source_page: Trang nguá»“n
            damping_factor: Há»‡ sá»‘ damping (thÆ°á»ng lÃ  0.85)
            max_iterations: Sá»‘ iteration tá»‘i Ä‘a
            tolerance: NgÆ°á»¡ng há»™i tá»¥

        Returns:
            List[(page_id, pagerank_value)]
        """

        print(f"ğŸš€ Báº¯t Ä‘áº§u tÃ­nh Personalized PageRank vá»›i trang nguá»“n: {source_page}")
        print(f"ğŸ“Š Tá»•ng sá»‘ cáº¡nh: {len(edges)}")

        # BÆ°á»›c 1: Táº¡o RDD tá»« danh sÃ¡ch edges
        edges_rdd = self.sc.parallelize(edges)

        # BÆ°á»›c 2: XÃ¢y dá»±ng cáº¥u trÃºc Ä‘á»“ thá»‹ - adjacency list
        # Táº¡o outlinks: page_id -> [list_of_outgoing_pages]
        outlinks = edges_rdd \
            .groupByKey() \
            .mapValues(list) \
            .persist(StorageLevel.MEMORY_AND_DISK)

        # Láº¥y táº¥t cáº£ cÃ¡c trang duy nháº¥t
        all_pages = edges_rdd.flatMap(lambda edge: [edge[0], edge[1]]).distinct()
        all_pages_list = all_pages.collect()

        print(f"ğŸ“ Tá»•ng sá»‘ trang: {len(all_pages_list)}")

        # BÆ°á»›c 3: Khá»Ÿi táº¡o PageRank
        # Trang nguá»“n = 1.0, cÃ¡c trang khÃ¡c = 0.0
        def initialize_rank(page_id):
            return 1.0 if page_id == source_page else 0.0

        page_ranks = all_pages.map(lambda page: (page, initialize_rank(page))) \
            .persist(StorageLevel.MEMORY_AND_DISK)

        print("âœ… Khá»Ÿi táº¡o PageRank hoÃ n thÃ nh")

        # BÆ°á»›c 4: TÃ­nh toÃ¡n láº·p
        iteration = 0
        converged = False
        previous_ranks = None

        while iteration < max_iterations and not converged:
            iteration += 1

            # TÃ­nh contributions tá»« má»—i trang Ä‘áº¿n cÃ¡c trang Ä‘Ã­ch
            contributions = page_ranks \
                .join(outlinks) \
                .flatMap(lambda x: self._calculate_contributions(x[0], x[1][0], x[1][1]))

            # Tá»•ng há»£p contributions cho má»—i trang
            aggregated_contributions = contributions.reduceByKey(lambda a, b: a + b)

            # TÃ­nh PageRank má»›i
            new_page_ranks = all_pages.map(lambda page: (page, 0.0)) \
                .leftOuterJoin(aggregated_contributions) \
                .map(lambda x: self._calculate_new_rank(
                x[0], x[1][1], source_page, damping_factor
            )) \
                .persist(StorageLevel.MEMORY_AND_DISK)

            # Kiá»ƒm tra há»™i tá»¥
            if iteration > 1:
                rank_differences = previous_ranks.join(new_page_ranks) \
                    .map(lambda x: abs(x[1][1] - x[1][0]))

                max_difference = rank_differences.max()
                converged = max_difference < tolerance

                print(f"ğŸ”„ Iteration {iteration}: Max difference = {max_difference:.8f}")

            # Cáº­p nháº­t cho iteration tiáº¿p theo
            if previous_ranks:
                previous_ranks.unpersist()
            previous_ranks = page_ranks
            page_ranks = new_page_ranks

        # Káº¿t thÃºc
        if converged:
            print(f"âœ… Há»™i tá»¥ sau {iteration} iterations")
        else:
            print(f"âš ï¸  Äáº¡t sá»‘ iteration tá»‘i Ä‘a ({max_iterations})")

        # Láº¥y káº¿t quáº£
        results = page_ranks.collect()

        # Dá»n dáº¹p
        outlinks.unpersist()
        if previous_ranks:
            previous_ranks.unpersist()
        page_ranks.unpersist()

        return results

    def _calculate_contributions(self, page_id: str, rank: float, outgoing_pages: List[str]):
        """TÃ­nh contribution tá»« má»™t trang Ä‘áº¿n cÃ¡c trang Ä‘Ã­ch"""
        if not outgoing_pages:
            return []

        contribution_per_page = rank / len(outgoing_pages)
        return [(target_page, contribution_per_page) for target_page in outgoing_pages]

    def _calculate_new_rank(self, page_id: str, contribution_opt, source_page: str, damping_factor: float):
        """TÃ­nh PageRank má»›i cho má»™t trang"""
        contribution = contribution_opt if contribution_opt is not None else 0.0

        if page_id == source_page:
            # Trang nguá»“n: damped contribution + jump probability
            new_rank = damping_factor * contribution + (1.0 - damping_factor)
        else:
            # Trang khÃ¡c: chá»‰ cÃ³ damped contribution
            new_rank = damping_factor * contribution

        return (page_id, new_rank)

    def compute_with_dataframes(
            self,
            edges: List[Tuple[str, str]],
            source_page: str,
            damping_factor: float = 0.85,
            max_iterations: int = 100,
            tolerance: float = 1e-6
    ) -> List[Tuple[str, float]]:
        """
        TÃ­nh Personalized PageRank sá»­ dá»¥ng DataFrame (cÃ¡ch tiáº¿p cáº­n hiá»‡n Ä‘áº¡i hÆ¡n)
        """

        print(f"ğŸš€ TÃ­nh PageRank báº±ng DataFrame vá»›i trang nguá»“n: {source_page}")

        # Táº¡o DataFrame tá»« edges
        edges_df = self.spark.createDataFrame(edges, ["from_page", "to_page"])

        # Láº¥y táº¥t cáº£ trang duy nháº¥t
        all_pages_df = edges_df.select(col("from_page").alias("page_id")) \
            .union(edges_df.select(col("to_page").alias("page_id"))) \
            .distinct()

        # Khá»Ÿi táº¡o ranks
        initial_ranks_df = all_pages_df.withColumn(
            "rank",
            when(col("page_id") == source_page, 1.0).otherwise(0.0)
        )

        # Táº¡o adjacency list
        outlinks_df = edges_df.groupBy("from_page") \
            .agg(collect_list("to_page").alias("outlinks"))

        current_ranks_df = initial_ranks_df

        for iteration in range(1, max_iterations + 1):
            print(f"ğŸ”„ DataFrame Iteration {iteration}")

            # TÃ­nh contributions (phá»©c táº¡p hÆ¡n vá»›i DataFrame)
            # Äá»ƒ Ä‘Æ¡n giáº£n, chÃºng ta convert vá» RDD cho pháº§n nÃ y
            current_ranks_rdd = current_ranks_df.rdd.map(lambda row: (row.page_id, row.rank))
            outlinks_rdd = outlinks_df.rdd.map(lambda row: (row.from_page, row.outlinks))

            # ... (logic tÆ°Æ¡ng tá»± nhÆ° RDD version)
            break  # Placeholder - implementation Ä‘áº§y Ä‘á»§ sáº½ phá»©c táº¡p hÆ¡n

        return current_ranks_df.collect()

    def load_edges_from_file(self, file_path: str) -> List[Tuple[str, str]]:
        """Äá»c edges tá»« file text"""
        try:
            edges_rdd = self.sc.textFile(file_path) \
                .map(lambda line: line.strip().split()) \
                .filter(lambda parts: len(parts) >= 2) \
                .map(lambda parts: (parts[0], parts[1]))

            return edges_rdd.collect()
        except Exception as e:
            print(f"âŒ Lá»—i khi Ä‘á»c file: {e}")
            return []

    def save_results(self, results: List[Tuple[str, float]], output_path: str):
        """LÆ°u káº¿t quáº£ ra file"""
        try:
            results_rdd = self.sc.parallelize(results) \
                .map(lambda x: f"{x[0]}\t{x[1]:.6f}")

            results_rdd.saveAsTextFile(output_path)
            print(f"âœ… ÄÃ£ lÆ°u káº¿t quáº£ táº¡i: {output_path}")
        except Exception as e:
            print(f"âŒ Lá»—i khi lÆ°u file: {e}")

    def validate_results(self, results: List[Tuple[str, float]]):
        """Kiá»ƒm tra tÃ­nh há»£p lá»‡ cá»§a káº¿t quáº£"""
        total_rank = sum(rank for _, rank in results)
        print(f"ğŸ“Š Tá»•ng PageRank: {total_rank:.6f}")

        # Trong Personalized PageRank, tá»•ng rank sáº½ khÃ¡c vá»›i PageRank thÃ´ng thÆ°á»ng
        print(f"ğŸ“ˆ CÃ¡c trang cÃ³ rank cao nháº¥t:")
        sorted_results = sorted(results, key=lambda x: x[1], reverse=True)
        for i, (page_id, rank) in enumerate(sorted_results[:5]):
            print(f"   {i + 1}. {page_id}: {rank:.6f}")

    def stop(self):
        """Dá»«ng Spark Session"""
        self.spark.stop()


def main():
    """HÃ m main Ä‘á»ƒ test"""

    # Khá»Ÿi táº¡o PersonalizedPageRank
    ppr = PersonalizedPageRank()

    try:
        # VÃ­ dá»¥ Ä‘á»“ thá»‹ Ä‘Æ¡n giáº£n: A -> B -> C -> A
        print("=" * 50)
        print("ğŸ§ª TEST Vá»šI Äá»’ THá»Š Äá»šN GIáº¢N")
        print("=" * 50)

        edges = [
            ("A", "B"),
            ("B", "C"),
            ("C", "A"),
            ("A", "C"),  # ThÃªm cáº¡nh Ä‘á»ƒ phá»©c táº¡p hÆ¡n
            ("B", "A")
        ]

        # TÃ­nh Personalized PageRank vá»›i A lÃ  source
        print("\nğŸ¯ TÃ­nh vá»›i trang nguá»“n = A")
        results_A = ppr.compute_personalized_pagerank(
            edges=edges,
            source_page="A",
            damping_factor=0.85,
            max_iterations=20,
            tolerance=1e-6
        )

        print("\nğŸ“Š Káº¾T QUáº¢ Vá»šI SOURCE = A:")
        ppr.validate_results(results_A)

        print("\n" + "=" * 30)

        # TÃ­nh vá»›i B lÃ  source Ä‘á»ƒ so sÃ¡nh
        print("\nğŸ¯ TÃ­nh vá»›i trang nguá»“n = B")
        results_B = ppr.compute_personalized_pagerank(
            edges=edges,
            source_page="B",
            damping_factor=0.85,
            max_iterations=20,
            tolerance=1e-6
        )

        print("\nğŸ“Š Káº¾T QUáº¢ Vá»šI SOURCE = B:")
        ppr.validate_results(results_B)

        # So sÃ¡nh káº¿t quáº£
        print("\nğŸ” SO SÃNH Káº¾T QUáº¢:")
        print("Source A vs Source B:")
        results_A_dict = dict(results_A)
        results_B_dict = dict(results_B)

        for page in ["A", "B", "C"]:
            rank_A = results_A_dict.get(page, 0)
            rank_B = results_B_dict.get(page, 0)
            print(f"  Trang {page}: Source=A ({rank_A:.4f}) vs Source=B ({rank_B:.4f})")

    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # Dá»«ng Spark
        ppr.stop()


def example_with_larger_graph():
    """VÃ­ dá»¥ vá»›i Ä‘á»“ thá»‹ lá»›n hÆ¡n"""

    ppr = PersonalizedPageRank("LargerGraph-PageRank")

    try:
        # Äá»“ thá»‹ phá»©c táº¡p hÆ¡n
        edges = [
            ("A", "B"), ("A", "C"), ("A", "D"),
            ("B", "C"), ("B", "E"),
            ("C", "D"), ("C", "F"),
            ("D", "A"), ("D", "F"),
            ("E", "B"), ("E", "F"),
            ("F", "A"), ("F", "C")
        ]

        print("ğŸ—ï¸  Äá»’ THá»Š PHá»¨C Táº P Há»šN")
        print(f"Sá»‘ cáº¡nh: {len(edges)}")
        print(f"CÃ¡c cáº¡nh: {edges}")

        # TÃ­nh vá»›i nhiá»u source khÃ¡c nhau
        for source in ["A", "D", "F"]:
            print(f"\nğŸ¯ Source = {source}")
            results = ppr.compute_personalized_pagerank(
                edges=edges,
                source_page=source,
                damping_factor=0.85,
                max_iterations=50
            )

            print(f"ğŸ“Š Top 3 trang quan trá»ng nháº¥t tá»« {source}:")
            sorted_results = sorted(results, key=lambda x: x[1], reverse=True)
            for i, (page_id, rank) in enumerate(sorted_results[:3]):
                print(f"   {i + 1}. {page_id}: {rank:.6f}")

    finally:
        ppr.stop()


if __name__ == "__main__":
    print("ğŸ PERSONALIZED PAGERANK Vá»šI PYSPARK")
    print("=" * 60)

    # Cháº¡y test cÆ¡ báº£n
    main()

    print("\n" + "=" * 60)
    print("ğŸ” TEST Vá»šI Äá»’ THá»Š Lá»šN Há»šN")
    print("=" * 60)

    # Cháº¡y test vá»›i Ä‘á»“ thá»‹ phá»©c táº¡p
    example_with_larger_graph()

    print("\nâœ… HOÃ€N THÃ€NH Táº¤T Cáº¢ TEST!")